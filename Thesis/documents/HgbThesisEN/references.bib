@online{Statista2024,
	author={ARtillery Intelligence},
	title={{Mobile augmented Reality (AR) users worldwide from 2023 to 2028}},
	date={2024},
	url={https://www.statista.com/statistics/1098630/global-mobile-augmented-reality-ar-users/},
	urldate={2025-08-31},
	langid={english}
}

@inproceedings{ChengYiFei2022TUDR,
	abstract = {Diminished reality (DR) refers to the concept of removing content from a user’s visual environment. While its implementation is becoming feasible, it is still unclear how users perceive and interact in DR-enabled environments and what applications it benefits. To address this challenge, we first conduct a formative study to compare user perceptions of DR and mediated reality effects (e. g., changing the color or size of target elements) in four example scenarios. Participants preferred removing objects through opacity reduction (i. e., the standard DR implementation) and appreciated mechanisms for maintaining a contextual understanding of diminished items (e. g., outlining). In a second study, we explore the user experience of performing tasks within DR-enabled environments. Participants selected which objects to diminish and the magnitude of the effects when performing two separate tasks (video viewing, assembly). Participants were comfortable with decreased contextual understanding, particularly for less mobile tasks. Based on the results, we define guidelines for creating general DR-enabled environments.},
	pages = {1--16},
	publisher = {ACM},
	booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
	isbn = {9781450391573},
	year = {2022},
	title = {Towards Understanding Diminished Reality},
	copyright = {2022 ACM},
	language = {eng},
	address = {New York, NY, USA},
	author = {Cheng, Yi Fei and Yin, Hang and Yan, Yukang and Gugenheimer, Jan and Lindlbauer, David},
}

@inproceedings{Milgram1994,
	author = {Paul Milgram and Haruo Takemura and Akira Utsumi and Fumio Kishino},
	title = {{Augmented reality: a class of displays on the reality-virtuality continuum}},
	volume = {2351},
	booktitle = {Telemanipulator and Telepresence Technologies},
	editor = {Hari Das},
	organization = {International Society for Optics and Photonics},
	publisher = {SPIE},
	pages = {282 -- 292},
	year = {1995},
	doi = {10.1117/12.197321},
	URL = {https://doi.org/10.1117/12.197321}
}

@article{DingRam2019,
	issn = {1057-7149},
	abstract = {Nonlocal texture similarity and local intensity smoothness are both essential for solving most image inpainting problems. In this paper, we propose a novel image inpainting algorithm that is capable of reproducing the underlying textural details using a nonlocal texture measure and also smoothing pixel intensity seamlessly in order to achieve natural-looking inpainted images. For matching texture, we propose a Gaussian-weighted nonlocal texture similarity measure to obtain multiple candidate patches for each target patch. To compute the pixel intensity, we apply the α-trimmed mean filter to the candidate patches to inpaint the target patch pixel-by-pixel. The proposed algorithm is compared with four current image inpainting algorithms under different scenarios, including object removal, texture synthesis, and error concealment. Experimental results show that the proposed algorithm outperforms the existing algorithms when inpainting large missing regions in images with texture and geometric structures.},
	journal = {IEEE transactions on image processing},
	pages = {1705--1719},
	volume = {28},
	publisher = {IEEE},
	number = {4},
	year = {2019},
	title = {Image Inpainting Using Nonlocal Texture Matching and Nonlinear Filtering},
	copyright = {Copyright The Institute of Electrical and Electronics Engineers, Inc. (IEEE) 2019},
	language = {eng},
	address = {United States},
	author = {Ding Ding and Ram, Sundaresh and Rodriguez, Jeffrey J.},
	keywords = {Algorithms ; Filters and filtration ; Image processing ; Image reconstruction ; Indexes ; Random access memory ; Resemblance (Philosophy) ; Texture},
}

@article{Weiwei2021,
	issn = {2169-3536},
	abstract = {Image inpainting is a challenging reconstruction of the damaged image in photography, especially for more valued artwork than before. The damages are mostly caused by scratches and worn out, so they cannot be easily fixed physically. Thus, many scientists proposed sophisticated methods for restoring the damaged image into a new one similar to an original image. However, these methods have not solved the problem effectively if the missing region is large. In this paper, we focus on how to restore a large missing region in image inpainting. This algorithm is composed of two steps: structure propagation and color propagation. In structure propagation, we segment a large region (non-homogeneous) into several small regions (homogeneous) based on the salient structure of missing region. Then, we applied a simple pixel-based inpainting method called the Fast Marching Method (FMM) to fill in the missing homogeneous regions by color propagation. In the experimental section, we applied several kinds of missing regions, such as irregular and regular missing regions, in large sizes. The results show that our proposed method performs well in various conditions.},
	journal = {IEEE Access},
	pages = {56430--56442},
	volume = {9},
	publisher = {IEEE},
	year = {2021},
	title = {Interactive Image Inpainting of Large-Scale Missing Region},
	copyright = {Copyright The Institute of Electrical and Electronics Engineers, Inc. (IEEE) 2021},
	language = {eng},
	address = {Piscataway},
	author = {Sari, Irawati Nurmala and Horikawa, Emiko and Du, Weiwei},
	keywords = {Algorithms ; Color ; Flow charts ; Image processing ; Image reconstruction ; Image segmentation ; Propagation},
}

@article{MuziHao2023,
	issn = {2078-2489},
	abstract = {Image inpainting aims to synthesize missing regions in images that are coherent with the existing visual content. Generative adversarial networks have made significant strides in the development of image inpainting. However, existing approaches heavily rely on the surrounding pixels while ignoring that the boundaries might be uninformative or noisy, leading to blurred images. As complementary, global visual features from the remote image contexts depict the overall structure and texture of the vanilla images, contributing to generating pixels that blend seamlessly with the existing visual elements. In this paper, we propose a novel model, PA-DeepFill, to repair high-resolution images. The generator network follows a novel progressive learning paradigm, starting with low-resolution images and gradually improving the resolutions by stacking more layers. A novel attention-based module, the gathered attention block, is further integrated into the generator to learn the importance of different distant visual components adaptively. In addition, we have designed a local discriminator that is more suitable for image inpainting tasks, multi-task guided mask-level local discriminator based PatchGAN, which can guide the model to distinguish between regions from the original image and regions completed by the model at a finer granularity. This local discriminator can capture more detailed local information, thereby enhancing the model’s discriminative ability and resulting in more realistic and natural inpainted images. Our proposal is extensively evaluated over popular datasets, and the experimental results demonstrate the superiority of our proposal.},
	journal = {Information (Basel)},
	pages = {512},
	volume = {14},
	publisher = {MDPI AG},
	number = {9},
	year = {2023},
	title = {Progressive-Augmented-Based DeepFill for High-Resolution Image Inpainting},
	copyright = {COPYRIGHT 2023 MDPI AG},
	language = {eng},
	address = {Basel},
	author = {Cui, Muzi and Jiang, Hao and Li, Chaozhuo},
	keywords = {Algorithms ; Differential equations Partial ; Methodology ; Methods ; Semantics ; Visual discrimination},
}



